{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Organising Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import patches as patches\n",
    "import matplotlib.lines as mlines\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import patches as patches\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "from our_som1A import SOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year AD</th>\n",
       "      <th>Year BS</th>\n",
       "      <th>Crop</th>\n",
       "      <th>Area</th>\n",
       "      <th>Production</th>\n",
       "      <th>Yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1984/85</td>\n",
       "      <td>2041/42</td>\n",
       "      <td>OILSEED</td>\n",
       "      <td>127820</td>\n",
       "      <td>84030</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1985/86</td>\n",
       "      <td>2042/43</td>\n",
       "      <td>OILSEED</td>\n",
       "      <td>137920</td>\n",
       "      <td>78390</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1986/87</td>\n",
       "      <td>2043/44</td>\n",
       "      <td>OILSEED</td>\n",
       "      <td>142890</td>\n",
       "      <td>82500</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1987/88</td>\n",
       "      <td>2044/45</td>\n",
       "      <td>OILSEED</td>\n",
       "      <td>151490</td>\n",
       "      <td>94370</td>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1988/89</td>\n",
       "      <td>2045/46</td>\n",
       "      <td>OILSEED</td>\n",
       "      <td>154860</td>\n",
       "      <td>99190</td>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1989/90</td>\n",
       "      <td>2046/47</td>\n",
       "      <td>OILSEED</td>\n",
       "      <td>153660</td>\n",
       "      <td>98060</td>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1990/91</td>\n",
       "      <td>2047/48</td>\n",
       "      <td>OILSEED</td>\n",
       "      <td>156310</td>\n",
       "      <td>92140</td>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1991/92</td>\n",
       "      <td>2048/49</td>\n",
       "      <td>OILSEED</td>\n",
       "      <td>154570</td>\n",
       "      <td>87840</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1992/93</td>\n",
       "      <td>2049/50</td>\n",
       "      <td>OILSEED</td>\n",
       "      <td>165240</td>\n",
       "      <td>93690</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1993/94</td>\n",
       "      <td>2050/51</td>\n",
       "      <td>OILSEED</td>\n",
       "      <td>177486</td>\n",
       "      <td>107535</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year AD  Year BS     Crop    Area  Production  Yield\n",
       "0  1984/85  2041/42  OILSEED  127820       84030    657\n",
       "1  1985/86  2042/43  OILSEED  137920       78390    568\n",
       "2  1986/87  2043/44  OILSEED  142890       82500    577\n",
       "3  1987/88  2044/45  OILSEED  151490       94370    623\n",
       "4  1988/89  2045/46  OILSEED  154860       99190    641\n",
       "5  1989/90  2046/47  OILSEED  153660       98060    638\n",
       "6  1990/91  2047/48  OILSEED  156310       92140    589\n",
       "7  1991/92  2048/49  OILSEED  154570       87840    568\n",
       "8  1992/93  2049/50  OILSEED  165240       93690    567\n",
       "9  1993/94  2050/51  OILSEED  177486      107535    606"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading data\n",
    "data = pd.read_csv(\"cash-crops-nepal.csv\")\n",
    "# visualize some data\n",
    "data.iloc[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OILSEED' 'POTATO' 'TOBACCO' 'SUGARCANE' 'JUTE']\n"
     ]
    }
   ],
   "source": [
    "# What are the different crops\n",
    "print(data.iloc[:,2].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not use \"Crop\" labels for training SOM. But we will use it to check if the clustering by SOM worked fine or not. We will also drop the “Year AD” and “Year BS” columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Production</th>\n",
       "      <th>Yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>48800</td>\n",
       "      <td>1762580</td>\n",
       "      <td>36118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>37410</td>\n",
       "      <td>1291340</td>\n",
       "      <td>34519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>59425</td>\n",
       "      <td>2305326</td>\n",
       "      <td>38794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>186741</td>\n",
       "      <td>132865</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>186720</td>\n",
       "      <td>124931</td>\n",
       "      <td>669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>14450</td>\n",
       "      <td>15800</td>\n",
       "      <td>1093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6028</td>\n",
       "      <td>5447</td>\n",
       "      <td>904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>182110</td>\n",
       "      <td>119250</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>6130</td>\n",
       "      <td>5510</td>\n",
       "      <td>899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>179216</td>\n",
       "      <td>110226</td>\n",
       "      <td>615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Area  Production  Yield\n",
       "76   48800     1762580  36118\n",
       "70   37410     1291340  34519\n",
       "82   59425     2305326  38794\n",
       "19  186741      132865    711\n",
       "18  186720      124931    669\n",
       "87   14450       15800   1093\n",
       "52    6028        5447    904\n",
       "12  182110      119250    655\n",
       "53    6130        5510    899\n",
       "13  179216      110226    615"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffling data\n",
    "agri_data = data.iloc[np.random.permutation(len(data))]\n",
    "trunc_data = agri_data[[\"Area\", \"Production\", \"Yield\"]]\n",
    "trunc_data.iloc[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Production</th>\n",
       "      <th>Yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.256263</td>\n",
       "      <td>0.741794</td>\n",
       "      <td>0.898078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.196451</td>\n",
       "      <td>0.543470</td>\n",
       "      <td>0.858319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.312059</td>\n",
       "      <td>0.970213</td>\n",
       "      <td>0.964617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.980633</td>\n",
       "      <td>0.055917</td>\n",
       "      <td>0.017679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.980523</td>\n",
       "      <td>0.052578</td>\n",
       "      <td>0.016635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.075881</td>\n",
       "      <td>0.006650</td>\n",
       "      <td>0.027178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.031655</td>\n",
       "      <td>0.002292</td>\n",
       "      <td>0.022478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.956314</td>\n",
       "      <td>0.050187</td>\n",
       "      <td>0.016287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.032190</td>\n",
       "      <td>0.002319</td>\n",
       "      <td>0.022354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.941117</td>\n",
       "      <td>0.046389</td>\n",
       "      <td>0.015292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Area  Production     Yield\n",
       "76  0.256263    0.741794  0.898078\n",
       "70  0.196451    0.543470  0.858319\n",
       "82  0.312059    0.970213  0.964617\n",
       "19  0.980633    0.055917  0.017679\n",
       "18  0.980523    0.052578  0.016635\n",
       "87  0.075881    0.006650  0.027178\n",
       "52  0.031655    0.002292  0.022478\n",
       "12  0.956314    0.050187  0.016287\n",
       "53  0.032190    0.002319  0.022354\n",
       "13  0.941117    0.046389  0.015292"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (custom choice for) normalizing data\n",
    "trunc_data = trunc_data / trunc_data.max()\n",
    "trunc_data.iloc[:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training SOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s train the data in a 3 x 3 SOM network using 3 input features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# som = SOM(x_size, y_size, num_features)\n",
    "agri_som = SOM(3,3,3)\n",
    "\n",
    "# Initial weights\n",
    "init_fig = plt.figure()\n",
    "agri_som.show_plot(init_fig, 1, 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random weights (3 features) are given to each of 9 (3×3) neurons. The above figure shows how the neural network looks like in the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice: \n",
    "\n",
    "- after 60 Epochs, the network changed from random colors (initialization) to nearly constant color; this means that initial neighbourhood is large, so each neuron’s weight are being adjusted according to data.\n",
    "\n",
    "- Slowly, the network develops different color according to input data structures/patterns, but, you can notice similar colors are neighbors to one another.\n",
    "\n",
    "- Since there was a random initialization, the positions of colors may change but the topology will be preserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df, agri_som):\n",
    "    \"\"\"\n",
    "    finds the Best Matching Unit for each data sample.\n",
    "    Thus, the neuron with closest distance from data sample.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): df to be updated\n",
    "        agri_som (obj): model\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: updated df\n",
    "    \"\"\"\n",
    "    bmu, bmu_idx = agri_som.find_bmu(df.values)\n",
    "    df['bmu'] = bmu\n",
    "    df['bmu_idx'] = bmu_idx\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def arrange_data(agri_som):\n",
    "    \"\"\"\n",
    "    Fetch BMU of data samples and append them to the filtered agri_dataset    \n",
    "\n",
    "    Args:\n",
    "        agri_som (object): SOM model\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: updated agri_data with BMU\n",
    "    \"\"\"\n",
    "    clustered_df = trunc_data.apply(predict, axis=1, agri_som=agri_som)\n",
    "    joined_df = agri_data.join(clustered_df, rsuffix=\"_norm\")\n",
    "    return joined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def external_purity(df):\n",
    "    \"\"\"Purity measures the purity of clusters with respect to ground-truth class labels. To compute the purity of a clustering Q, \n",
    "    each cluster is assigned to the class which is most frequent in the cluster, and then the accuracy of this assignment is measured \n",
    "    by counting the number of correctly assigned points and dividing by the total number of points:\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): joined training set with bmu positions and weights\n",
    "    \"\"\"\n",
    "\n",
    "    # proper representation of column\n",
    "    df['bmu_idx'] = df['bmu_idx'].apply(lambda k: str(k))\n",
    "    df['bmu'] = df['bmu'].apply(lambda k: k[0])\n",
    "\n",
    "    # fetch number of different samples associated to each cluster.\n",
    "    clusters = df.value_counts(subset=['Crop', 'bmu_idx']).reset_index() \n",
    "    clusters.rename(columns={0:'count'}, inplace=True)\n",
    "\n",
    "    total = np.sum(clusters['count'])  # compute total number of points clustered\n",
    "\n",
    "    # assign class which is most frequent in the cluster. highest count of that specific crop type in cluster\n",
    "    cluster_dominated = clusters.groupby(by=['Crop']).max().reset_index()\n",
    "    total_correct = np.sum(cluster_dominated['count'])  # compute total number of correctly clustered\n",
    "    \n",
    "    return total_correct/total\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def visualize(joined_df, lr, lf,agri_som):\n",
    "    fig = plt.figure()\n",
    "    # setup axes\n",
    "    ax = fig.add_subplot(111)\n",
    "    scale = 50\n",
    "    ax.set_xlim((0, agri_som.net.shape[0]*scale))\n",
    "    ax.set_ylim((0, agri_som.net.shape[1]*scale))\n",
    "    ax.set_title(\"learning function: \"+lf+\", learning rate: \"+str(lr))\n",
    "\n",
    "    for x in range(0, agri_som.net.shape[0]):\n",
    "        for y in range(0, agri_som.net.shape[1]):\n",
    "            ax.add_patch(patches.Rectangle((x*scale, y*scale), scale, scale,\n",
    "                         facecolor='white',\n",
    "                         edgecolor='grey'))\n",
    "    legend_map = {}\n",
    "\n",
    "    for index, row in joined_df.iterrows():\n",
    "        x_cor = row['bmu_idx'][0] * scale\n",
    "        y_cor = row['bmu_idx'][1] * scale\n",
    "        x_cor = np.random.randint(x_cor, x_cor + scale)\n",
    "        y_cor = np.random.randint(y_cor, y_cor + scale)\n",
    "        color = row['bmu'][0]\n",
    "        marker = \"$\\\\ \" + row['Crop'][0]+\"$\"\n",
    "        marker = marker.lower()\n",
    "        ax.plot(x_cor, y_cor, color=color, marker=marker, markersize=10)\n",
    "        label = row['Crop']\n",
    "        if not label in legend_map:\n",
    "            legend_map[label] =  mlines.Line2D([], [], color='black', marker=marker, linestyle='None',\n",
    "                              markersize=10, label=label)\n",
    "    plt.legend(handles=list(legend_map.values()), bbox_to_anchor=(1, 1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "executes SOM for epochs [5, 10, 20, 30, 40, 50]\n",
    "\"\"\"\n",
    "\n",
    "external_purities_5 = []\n",
    "def run_5(weights, base_lr, lr_decay_function, show_plot=False):\n",
    "    \"\"\"wrapper function for 5 epochs. implements the SOM with the given parameters\n",
    "\n",
    "    Args:\n",
    "        weights (np.ndarray): weights to be used for network grid.\n",
    "        base_lr (float): base learning rate to perform the SOM algorithm with.\n",
    "        lr_decay_function (str): one of the 4 implemented decay functions. [default (gaussian), linear, inverse, power (exponential)]\n",
    "    \"\"\"\n",
    "    agri_som = SOM(3,3,3)  # initialization\n",
    "    agri_som.set_weights(weights)\n",
    "\n",
    "    agri_som.train(trunc_data.values,\n",
    "          num_epochs=5,\n",
    "          init_learning_rate=base_lr,\n",
    "          lr_decay_function=lr_decay_function,\n",
    "          show_plot=show_plot,\n",
    "          )\n",
    "    joined_df = arrange_data(agri_som)\n",
    "    # visualize(joined_df, lr, lf, agri_som)\n",
    "\n",
    "    # combine external purity with computed mean-absolute-error\n",
    "    ext_purity = round(external_purity(joined_df), 3)\n",
    "    mae = round(np.mean(np.abs(agri_som.approx_net-agri_som.net)), 3)\n",
    "    pur_mae = f'{ext_purity} ({mae})'\n",
    "    external_purities_5.append(pur_mae)\n",
    "\n",
    "\n",
    "external_purities_10 = []\n",
    "def run_10(weights, base_lr, lr_decay_function, show_plot=False):\n",
    "    \"\"\"wrapper function for 10 epochs. implements the SOM with the given parameters\n",
    "\n",
    "    Args:\n",
    "        weights (np.ndarray): weights to be used for network grid.\n",
    "        base_lr (float): base learning rate to perform the SOM algorithm with.\n",
    "        lr_decay_function (str): one of the 4 implemented decay functions. [default (gaussian), linear, inverse, power (exponential)]\n",
    "    \"\"\"\n",
    "    agri_som = SOM(3,3,3)  # initialization\n",
    "    agri_som.set_weights(weights)\n",
    "\n",
    "    agri_som.train(trunc_data.values,\n",
    "          num_epochs=10,\n",
    "          init_learning_rate=base_lr,\n",
    "          lr_decay_function=lr_decay_function,\n",
    "          show_plot=show_plot,\n",
    "          )\n",
    "    joined_df = arrange_data(agri_som)\n",
    "    # visualize(joined_df, lr, lf, agri_som)\n",
    "\n",
    "    # combine external purity with computed mean-absolute-error\n",
    "    ext_purity = round(external_purity(joined_df), 3)\n",
    "    mae = round(np.mean(np.abs(agri_som.approx_net-agri_som.net)), 3)\n",
    "    pur_mae = f'{ext_purity} ({mae})'\n",
    "    external_purities_10.append(pur_mae)\n",
    "\n",
    "external_purities_20 = []\n",
    "def run_20(weights, base_lr, lr_decay_function, show_plot=False):\n",
    "    \"\"\"wrapper function for 20 epochs. implements the SOM with the given parameters\n",
    "\n",
    "    Args:\n",
    "        weights (np.ndarray): weights to be used for network grid.\n",
    "        base_lr (float): base learning rate to perform the SOM algorithm with.\n",
    "        lr_decay_function (str): one of the 4 implemented decay functions. [default (gaussian), linear, inverse, power (exponential)]\n",
    "    \"\"\"\n",
    "    agri_som = SOM(3,3,3)  # initialization\n",
    "    agri_som.set_weights(weights)\n",
    "\n",
    "    agri_som.train(trunc_data.values,\n",
    "          num_epochs=20,\n",
    "          init_learning_rate=base_lr,\n",
    "          lr_decay_function=lr_decay_function,\n",
    "          show_plot=show_plot,\n",
    "          )\n",
    "    joined_df = arrange_data(agri_som)\n",
    "    # visualize(joined_df, lr, lf, agri_som)\n",
    "    \n",
    "    # combine external purity with computed mean-absolute-error\n",
    "    ext_purity = round(external_purity(joined_df), 3)\n",
    "    mae = round(np.mean(np.abs(agri_som.approx_net-agri_som.net)), 3)\n",
    "    pur_mae = f'{ext_purity} ({mae})'\n",
    "    external_purities_20.append(pur_mae)\n",
    "\n",
    "\n",
    "external_purities_30 = []\n",
    "def run_30(weights, base_lr, lr_decay_function, show_plot=False):\n",
    "    \"\"\"wrapper function for 30 epochs. implements the SOM with the given parameters\n",
    "\n",
    "    Args:\n",
    "        weights (np.ndarray): weights to be used for network grid.\n",
    "        base_lr (float): base learning rate to perform the SOM algorithm with.\n",
    "        lr_decay_function (str): one of the 4 implemented decay functions. [default (gaussian), linear, inverse, power (exponential)]\n",
    "    \"\"\"\n",
    "    agri_som = SOM(3,3,3)  # initialization\n",
    "    agri_som.set_weights(weights)\n",
    "\n",
    "    agri_som.train(trunc_data.values,\n",
    "          num_epochs=30,\n",
    "          init_learning_rate=base_lr,\n",
    "          lr_decay_function=lr_decay_function,\n",
    "          show_plot=show_plot,\n",
    "          )\n",
    "    joined_df = arrange_data(agri_som)\n",
    "    # visualize(joined_df, lr, lf, agri_som)\n",
    "    \n",
    "    # combine external purity with computed mean-absolute-error\n",
    "    ext_purity = round(external_purity(joined_df), 3)\n",
    "    mae = round(np.mean(np.abs(agri_som.approx_net-agri_som.net)), 3)\n",
    "    pur_mae = f'{ext_purity} ({mae})'\n",
    "    external_purities_30.append(pur_mae)\n",
    "\n",
    "\n",
    "external_purities_40 = []\n",
    "def run_40(weights, base_lr, lr_decay_function, show_plot=False):\n",
    "    \"\"\"wrapper function for 40 epochs. implements the SOM with the given parameters\n",
    "\n",
    "    Args:\n",
    "        weights (np.ndarray): weights to be used for network grid.\n",
    "        base_lr (float): base learning rate to perform the SOM algorithm with.\n",
    "        lr_decay_function (str): one of the 4 implemented decay functions. [default (gaussian), linear, inverse, power (exponential)]\n",
    "    \"\"\"\n",
    "    agri_som = SOM(3,3,3)  # initialization\n",
    "    agri_som.set_weights(weights)\n",
    "\n",
    "    agri_som.train(trunc_data.values,\n",
    "          num_epochs=40,\n",
    "          init_learning_rate=base_lr,\n",
    "          lr_decay_function=lr_decay_function,\n",
    "          show_plot=show_plot,\n",
    "          )\n",
    "    joined_df = arrange_data(agri_som)\n",
    "    # visualize(joined_df, lr, lf, agri_som)\n",
    "    \n",
    "    # combine external purity with computed mean-absolute-error\n",
    "    ext_purity = round(external_purity(joined_df), 3)\n",
    "    mae = round(np.mean(np.abs(agri_som.approx_net-agri_som.net)), 3)\n",
    "    pur_mae = f'{ext_purity} ({mae})'\n",
    "    external_purities_40.append(pur_mae)\n",
    "\n",
    "\n",
    "external_purities_50 = []\n",
    "def run_50(weights, base_lr, lr_decay_function, show_plot=False):\n",
    "    \"\"\"wrapper function for 50 epochs. implements the SOM with the given parameters\n",
    "\n",
    "    Args:\n",
    "        weights (np.ndarray): weights to be used for network grid.\n",
    "        base_lr (float): base learning rate to perform the SOM algorithm with.\n",
    "        lr_decay_function (str): one of the 4 implemented decay functions. [default (gaussian), linear, inverse, power (exponential)]\n",
    "    \"\"\"\n",
    "    agri_som = SOM(3,3,3)  # initialization\n",
    "    agri_som.set_weights(weights)\n",
    "\n",
    "    agri_som.train(trunc_data.values,\n",
    "          num_epochs=50,\n",
    "          init_learning_rate=base_lr,\n",
    "          lr_decay_function=lr_decay_function,\n",
    "          show_plot=show_plot,\n",
    "          )\n",
    "    joined_df = arrange_data(agri_som)\n",
    "    # visualize(joined_df, lr, lf, agri_som)\n",
    "    \n",
    "    # combine external purity with computed mean-absolute-error\n",
    "    ext_purity = round(external_purity(joined_df), 3)\n",
    "    mae = round(np.mean(np.abs(agri_som.approx_net-agri_som.net)), 3)\n",
    "    pur_mae = f'{ext_purity} ({mae})'\n",
    "    external_purities_50.append(pur_mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More rates, and decay functions can be appended. cost is running time\n",
    "lrs = [1, 0.1]#, 0.01, 0.001]  # base learning rates\n",
    "lfs = [\"default\"]#, \"linear\", \"inverse\", \"power\"]  # learning rate decay functions\n",
    "epochs = [5,10,20,30,40,50]\n",
    "\n",
    "# 16 runs/combinations in all\n",
    "mesh = np.array(np.meshgrid(lrs, lfs))\n",
    "lrs_lfs = mesh.T.reshape(-1, 2)\n",
    "\n",
    "# agri_som = SOM(3,3,3)  # initialization\n",
    "# weights = agri_som.net\n",
    "weights = np.array(\n",
    "    [\n",
    "        [\n",
    "            [0.04039447, 0.6495641 , 0.46165352],\n",
    "            [0.9118578 , 0.28238622, 0.39812322],\n",
    "            [0.58684143, 0.11878689, 0.99220547]\n",
    "        ],\n",
    "       [\n",
    "            [0.46852085, 0.94825253, 0.61640755],\n",
    "            [0.80456765, 0.03104591, 0.45691878],\n",
    "            [0.29590234, 0.77207143, 0.81684638]\n",
    "        ],\n",
    "       [\n",
    "            [0.96509498, 0.26071734, 0.78689664],\n",
    "            [0.12195003, 0.47102914, 0.92465288],\n",
    "            [0.81227374, 0.46423983, 0.98292867]\n",
    "        ]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:1.0, lrf:default, epoch:5 done!\n",
      "lr:1.0, lrf:default, epoch:10 done!\n",
      "lr:1.0, lrf:default, epoch:20 done!\n",
      "lr:1.0, lrf:default, epoch:30 done!\n",
      "lr:1.0, lrf:default, epoch:40 done!\n",
      "lr:1.0, lrf:default, epoch:50 done!\n",
      "lr:0.1, lrf:default, epoch:5 done!\n",
      "lr:0.1, lrf:default, epoch:10 done!\n",
      "lr:0.1, lrf:default, epoch:20 done!\n",
      "lr:0.1, lrf:default, epoch:30 done!\n",
      "lr:0.1, lrf:default, epoch:40 done!\n",
      "lr:0.1, lrf:default, epoch:50 done!\n"
     ]
    }
   ],
   "source": [
    "# extract columns\n",
    "lrs_ = [_[0] for _ in lrs_lfs]\n",
    "lfs_ = [_[1] for _ in lrs_lfs]\n",
    "\n",
    "data = {\n",
    "    'learning_function': lfs_,\n",
    "    'learning_rate': lrs_,\n",
    "}\n",
    "\n",
    "# main runs\n",
    "for lr, lf in lrs_lfs:\n",
    "    lr = lr.astype('float64')\n",
    "\n",
    "    for epoch in epochs:\n",
    "        agri_som = SOM(3,3,3)  # initialization\n",
    "        agri_som.set_weights(weights)\n",
    "\n",
    "        agri_som.train(trunc_data.values,\n",
    "            num_epochs=epoch,\n",
    "            init_learning_rate=lr,\n",
    "            lr_decay_function=lf,\n",
    "            show_plot=False,\n",
    "            method = 'euler'\n",
    "            )\n",
    "        joined_df = arrange_data(agri_som)\n",
    "        # visualize(joined_df, lr, lf, agri_som)\n",
    "\n",
    "        # combine external purity with computed mean-absolute-error\n",
    "        ext_purity = round(external_purity(joined_df), 3)\n",
    "        mae = round(np.mean(np.abs(agri_som.approx_net-agri_som.net)), 3)\n",
    "        pur_mae = f'{ext_purity} ({mae})'\n",
    "\n",
    "        data.update({f'ext.purity_mae{epoch}': pur_mae})\n",
    "        \n",
    "        print(f'lr:{lr}, lrf:{lf}, epoch:{epoch} done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(\n",
    "    data, index=range(len(lfs_))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_function</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>ext.purity_mae5</th>\n",
       "      <th>ext.purity_mae10</th>\n",
       "      <th>ext.purity_mae20</th>\n",
       "      <th>ext.purity_mae30</th>\n",
       "      <th>ext.purity_mae40</th>\n",
       "      <th>ext.purity_mae50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.848 (0.003)</td>\n",
       "      <td>0.848 (0.003)</td>\n",
       "      <td>0.848 (0.006)</td>\n",
       "      <td>0.848 (0.005)</td>\n",
       "      <td>0.857 (0.009)</td>\n",
       "      <td>0.857 (0.006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>default</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.848 (0.003)</td>\n",
       "      <td>0.848 (0.003)</td>\n",
       "      <td>0.848 (0.006)</td>\n",
       "      <td>0.848 (0.005)</td>\n",
       "      <td>0.857 (0.009)</td>\n",
       "      <td>0.857 (0.006)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  learning_function learning_rate ext.purity_mae5 ext.purity_mae10  \\\n",
       "0           default           1.0   0.848 (0.003)    0.848 (0.003)   \n",
       "1           default           0.1   0.848 (0.003)    0.848 (0.003)   \n",
       "\n",
       "  ext.purity_mae20 ext.purity_mae30 ext.purity_mae40 ext.purity_mae50  \n",
       "0    0.848 (0.006)    0.848 (0.005)    0.857 (0.009)    0.857 (0.006)  \n",
       "1    0.848 (0.006)    0.848 (0.005)    0.857 (0.009)    0.857 (0.006)  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lr, lf \u001b[38;5;129;01min\u001b[39;00m lrs_lfs:\n\u001b[0;32m      3\u001b[0m     lr \u001b[38;5;241m=\u001b[39m lr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mrun\u001b[49m(epochs, weights, base_lr\u001b[38;5;241m=\u001b[39mlr, lr_decay_function\u001b[38;5;241m=\u001b[39mlf, show_plot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# run_5(weights, base_lr=lr, lr_decay_function=lf, show_plot=False)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# run_10(weights, base_lr=lr, lr_decay_function=lf, show_plot=False)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# run_20(weights, base_lr=lr, lr_decay_function=lf, show_plot=False)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# run_30(weights, base_lr=lr, lr_decay_function=lf, show_plot=False)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# run_40(weights, base_lr=lr, lr_decay_function=lf, show_plot=False)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# run_50(weights, base_lr=lr, lr_decay_function=lf, show_plot=False)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, lrf:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m done!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'run' is not defined"
     ]
    }
   ],
   "source": [
    "# main runs\n",
    "for lr, lf in lrs_lfs:\n",
    "    lr = lr.astype('float64')\n",
    "    run(epochs, weights, base_lr=lr, lr_decay_function=lf, show_plot=False)\n",
    "    # run_5(weights, base_lr=lr, lr_decay_function=lf, show_plot=False)\n",
    "    # run_10(weights, base_lr=lr, lr_decay_function=lf, show_plot=False)\n",
    "    # run_20(weights, base_lr=lr, lr_decay_function=lf, show_plot=False)\n",
    "    # run_30(weights, base_lr=lr, lr_decay_function=lf, show_plot=False)\n",
    "    # run_40(weights, base_lr=lr, lr_decay_function=lf, show_plot=False)\n",
    "    # run_50(weights, base_lr=lr, lr_decay_function=lf, show_plot=False)\n",
    "\n",
    "    print(f'lr:{lr}, lrf:{lf} done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Analyzing Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is implementation with euler optimization.\n",
    "For each epoch, the external purity and estimated mean-absolute-error(in brackets) is reported.\n",
    "\n",
    "Comments:\n",
    "\t- The estimated absolute error decreases for larger epochs.\n",
    "\t- Estimated absolute error decreases for smaller learning rates.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# extract columns\n",
    "lrs_ = [_[0] for _ in lrs_lfs]\n",
    "lfs_ = [_[1] for _ in lrs_lfs]\n",
    "\n",
    "data = {\n",
    "\t'learning_function': lfs_,\n",
    "\t'learning_rate': lrs_,\n",
    "\t'external_mae_5': external_purities_5, \n",
    "\t'external_mae_10': external_purities_10, \n",
    "\t'external_mae_20': external_purities_20,\n",
    "\t'external_mae_30': external_purities_30, \n",
    "\t'external_mae_40': external_purities_40, \n",
    "\t'external_mae_50': external_purities_50,\n",
    "}\n",
    "results_df = pd.DataFrame(\n",
    "\tdata\n",
    ")\n",
    "\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df['learning_function'] == 'default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics\n",
    "results_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Highest Accuracies\n",
    "# \"\"\"\n",
    "# Maximum Accuracy:\n",
    "# \t- inverse learning function (1.0, 0.1) learning rates at 500 epochs 93%\n",
    "# \t- default function, 1.0 learning rate. 10 epochs, 89%.\n",
    "# \t- power function, 0.001 learning rate, 400 epochs, 89%/.\n",
    "\n",
    "# \"\"\"\n",
    "# maxs = results_df.iloc[:,2:].idxmax().reset_index()\n",
    "# maxs.rename(columns={'index': 'column', 0: 'row'}, inplace=True)\n",
    "# max_rows = maxs['row'].values\n",
    "\n",
    "# # maximum rows for each epochs.\n",
    "# results_df[results_df.index.isin(max_rows)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Minimum\n",
    "# \"\"\"\n",
    "# Minimum Accuracy:\n",
    "# \t- inverse function, 1.0 learning rate, 100 epochs, 66%.\n",
    "# \"\"\"\n",
    "# mins = results_df.iloc[:,2:].idxmin().reset_index()\n",
    "# mins.rename(columns={'index': 'column', 0: 'row'}, inplace=True)\n",
    "# min_rows = mins['row'].values\n",
    "\n",
    "# # table of maximums by inspection from description, our best shot is row 12\n",
    "# results_df[results_df.index.isin(min_rows)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Individual Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # default\n",
    "# \"\"\"\n",
    "# - overall accuracy decreases with smaller learning rates.\n",
    "# - performance increases for larger epochs\n",
    "\n",
    "# \"\"\"\n",
    "# results_df[results_df['learning_function'] == 'default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # linear\n",
    "# \"\"\"\n",
    "# - overall accuracy decreases for smaller learning rates.\n",
    "# - accuracy decreases for larger epochs.\n",
    "# - not a good function.\n",
    "# \"\"\"\n",
    "# results_df[results_df['learning_function'] == 'linear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # inverse\n",
    "# \"\"\"\n",
    "# - overall accuracy increases for smaller learning rates but not for very very small rates (0.001)\n",
    "# - accuracy increases across larger epochs.\n",
    "# - a good function.\n",
    "# \"\"\"\n",
    "# results_df[results_df['learning_function'] == 'inverse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # power\n",
    "# \"\"\"\n",
    "# - overall accuracy decreases for smaller learning rates.\n",
    "# - accuracy increases across larger epochs.\n",
    "# - not a good function.\n",
    "# \"\"\"\n",
    "# results_df[results_df['learning_function'] == 'power']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Runge-Kutta**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "executes SOM for epochs [5, 10, 20, 30, 40, 50]\n",
    "\"\"\"\n",
    "\n",
    "external_purities_5 = []\n",
    "def run_5(weights, base_lr, lr_decay_function, show_plot=False):\n",
    "    \"\"\"wrapper function for 5 epochs. implements the SOM with the given parameters\n",
    "\n",
    "    Args:\n",
    "        weights (np.ndarray): weights to be used for network grid.\n",
    "        base_lr (float): base learning rate to perform the SOM algorithm with.\n",
    "        lr_decay_function (str): one of the 4 implemented decay functions. [default (gaussian), linear, inverse, power (exponential)]\n",
    "    \"\"\"\n",
    "    agri_som = SOM(3,3,3)  # initialization\n",
    "    agri_som.set_weights = weights\n",
    "\n",
    "    agri_som.train_runge_kutta(trunc_data.values,\n",
    "          num_epochs=5,\n",
    "          init_learning_rate=base_lr,\n",
    "          lr_decay_function=lr_decay_function,\n",
    "          show_plot=show_plot,\n",
    "          )\n",
    "    joined_df = arrange_data(agri_som)\n",
    "    # visualize(joined_df, lr, lf, agri_som)\n",
    "    external_purities_5.append(external_purity(joined_df))\n",
    "\n",
    "\n",
    "external_purities_10 = []\n",
    "def run_10(weights, base_lr, lr_decay_function, show_plot=False):\n",
    "    \"\"\"wrapper function for 10 epochs. implements the SOM with the given parameters\n",
    "\n",
    "    Args:\n",
    "        weights (np.ndarray): weights to be used for network grid.\n",
    "        base_lr (float): base learning rate to perform the SOM algorithm with.\n",
    "        lr_decay_function (str): one of the 4 implemented decay functions. [default (gaussian), linear, inverse, power (exponential)]\n",
    "    \"\"\"\n",
    "    agri_som = SOM(3,3,3)  # initialization\n",
    "    agri_som.train_runge_kutta(trunc_data.values,\n",
    "          num_epochs=10,\n",
    "          init_learning_rate=base_lr,\n",
    "          lr_decay_function=lr_decay_function,\n",
    "          show_plot=show_plot,\n",
    "          )\n",
    "    joined_df = arrange_data(agri_som)\n",
    "    # visualize(joined_df, lr, lf, agri_som)\n",
    "    external_purities_10.append(external_purity(joined_df))\n",
    "\n",
    "external_purities_20 = []\n",
    "def run_20(weights, base_lr, lr_decay_function, show_plot=False):\n",
    "    \"\"\"wrapper function for 20 epochs. implements the SOM with the given parameters\n",
    "\n",
    "    Args:\n",
    "        weights (np.ndarray): weights to be used for network grid.\n",
    "        base_lr (float): base learning rate to perform the SOM algorithm with.\n",
    "        lr_decay_function (str): one of the 4 implemented decay functions. [default (gaussian), linear, inverse, power (exponential)]\n",
    "    \"\"\"\n",
    "    agri_som = SOM(3,3,3)  # initialization\n",
    "    agri_som.set_weights = weights\n",
    "\n",
    "    agri_som.train_runge_kutta(trunc_data.values,\n",
    "          num_epochs=20,\n",
    "          init_learning_rate=base_lr,\n",
    "          lr_decay_function=lr_decay_function,\n",
    "          show_plot=show_plot,\n",
    "          )\n",
    "    joined_df = arrange_data(agri_som)\n",
    "    # visualize(joined_df, lr, lf, agri_som)\n",
    "    external_purities_20.append(external_purity(joined_df))\n",
    "\n",
    "\n",
    "external_purities_30 = []\n",
    "def run_30(weights, base_lr, lr_decay_function, show_plot=False):\n",
    "    \"\"\"wrapper function for 30 epochs. implements the SOM with the given parameters\n",
    "\n",
    "    Args:\n",
    "        weights (np.ndarray): weights to be used for network grid.\n",
    "        base_lr (float): base learning rate to perform the SOM algorithm with.\n",
    "        lr_decay_function (str): one of the 4 implemented decay functions. [default (gaussian), linear, inverse, power (exponential)]\n",
    "    \"\"\"\n",
    "    agri_som = SOM(3,3,3)  # initialization\n",
    "    agri_som.set_weights = weights\n",
    "\n",
    "    agri_som.train_runge_kutta(trunc_data.values,\n",
    "          num_epochs=30,\n",
    "          init_learning_rate=base_lr,\n",
    "          lr_decay_function=lr_decay_function,\n",
    "          show_plot=show_plot,\n",
    "          )\n",
    "    joined_df = arrange_data(agri_som)\n",
    "    # visualize(joined_df, lr, lf, agri_som)\n",
    "    external_purities_30.append(external_purity(joined_df))\n",
    "\n",
    "\n",
    "external_purities_40 = []\n",
    "def run_40(weights, base_lr, lr_decay_function, show_plot=False):\n",
    "    \"\"\"wrapper function for 40 epochs. implements the SOM with the given parameters\n",
    "\n",
    "    Args:\n",
    "        weights (np.ndarray): weights to be used for network grid.\n",
    "        base_lr (float): base learning rate to perform the SOM algorithm with.\n",
    "        lr_decay_function (str): one of the 4 implemented decay functions. [default (gaussian), linear, inverse, power (exponential)]\n",
    "    \"\"\"\n",
    "    agri_som = SOM(3,3,3)  # initialization\n",
    "    agri_som.set_weights = weights\n",
    "\n",
    "    agri_som.train_runge_kutta(trunc_data.values,\n",
    "          num_epochs=40,\n",
    "          init_learning_rate=base_lr,\n",
    "          lr_decay_function=lr_decay_function,\n",
    "          show_plot=show_plot,\n",
    "          )\n",
    "    joined_df = arrange_data(agri_som)\n",
    "    # visualize(joined_df, lr, lf, agri_som)\n",
    "    external_purities_40.append(external_purity(joined_df))\n",
    "\n",
    "\n",
    "external_purities_50 = []\n",
    "def run_50(weights, base_lr, lr_decay_function, show_plot=False):\n",
    "    \"\"\"wrapper function for 50 epochs. implements the SOM with the given parameters\n",
    "\n",
    "    Args:\n",
    "        weights (np.ndarray): weights to be used for network grid.\n",
    "        base_lr (float): base learning rate to perform the SOM algorithm with.\n",
    "        lr_decay_function (str): one of the 4 implemented decay functions. [default (gaussian), linear, inverse, power (exponential)]\n",
    "    \"\"\"\n",
    "    agri_som = SOM(3,3,3)  # initialization\n",
    "    agri_som.set_weights = weights\n",
    "\n",
    "    agri_som.train_runge_kutta(trunc_data.values,\n",
    "          num_epochs=50,\n",
    "          init_learning_rate=base_lr,\n",
    "          lr_decay_function=lr_decay_function,\n",
    "          show_plot=show_plot,\n",
    "          )\n",
    "    joined_df = arrange_data(agri_som)\n",
    "    # visualize(joined_df, lr, lf, agri_som)\n",
    "    external_purities_50.append(external_purity(joined_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for lr, lf in lrs_lfs:\n",
    "#     lr = lr.astype('float64')\n",
    "#     run_5(weights, base_lr=lr, lr_decay_function=lf, show_plot=False)\n",
    "#     run_10(weights, base_lr=lr, lr_decay_function=lf, show_plot=False)\n",
    "#     run_20(weights, base_lr=lr, lr_decay_function=lf, show_plot=False)\n",
    "#     run_30(weights, base_lr=lr, lr_decay_function=lf, show_plot=False)\n",
    "#     run_40(weights, base_lr=lr, lr_decay_function=lf, show_plot=False)\n",
    "#     run_50(weights, base_lr=lr, lr_decay_function=lf, show_plot=False)\n",
    "\n",
    "#     print(f'lr:{lr}, lrf:{lf} done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extract columns\n",
    "# lrs_ = [_[0] for _ in lrs_lfs]\n",
    "# lfs_ = [_[1] for _ in lrs_lfs]\n",
    "\n",
    "# data = {\n",
    "# \t'learning_function': lfs_,\n",
    "# \t'learning_rate': lrs_,\n",
    "# \t'external_purities_5': external_purities_5, \n",
    "# \t'external_purities_10': external_purities_10,\n",
    "# \t'external_purities_20': external_purities_20,\n",
    "# \t'external_purities_30': external_purities_30, \n",
    "# \t'external_purities_40': external_purities_40, \n",
    "# \t'external_purities_50': external_purities_50,\n",
    "# }\n",
    "# results_df_runge = pd.DataFrame(\n",
    "# \tdata, index=range(1, len(lrs_)+1)\n",
    "# )\n",
    "\n",
    "# results_df_runge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Descriptive statistics\n",
    "# results_df_runge.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # default\n",
    "# results_df_runge[results_df_runge['learning_function'] == 'default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # linear\n",
    "# results_df_runge[results_df_runge['learning_function'] == 'linear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # inverse\n",
    "# results_df_runge[results_df_runge['learning_function'] == 'inverse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # power\n",
    "# results_df_runge[results_df_runge['learning_function'] == 'power']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
